{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will compare the effects of Loss functions on a `LinearRegression` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Let's download a CSV file to use for this challenge and parse it into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Glazing Area</th>\n",
       "      <th>Average Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>14.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>28.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "74                   0.74         686.0      245.0     220.50             3.5   \n",
       "431                  0.62         808.5      367.5     220.50             3.5   \n",
       "616                  0.64         784.0      343.0     220.50             3.5   \n",
       "394                  0.86         588.0      294.0     147.00             7.0   \n",
       "144                  0.98         514.5      294.0     110.25             7.0   \n",
       "\n",
       "     Glazing Area  Average Temperature  \n",
       "74           0.10               11.920  \n",
       "431          0.25               14.170  \n",
       "616          0.40               20.460  \n",
       "394          0.25               28.905  \n",
       "144          0.10               24.980  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/loss_functions_dataset.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Your task is to predict the average temperature inside a greenhouse based on its design. Your temperature predictions will help you select the appropriate greenhouse design for each plant, based on their climate needs. \n",
    "\n",
    "üåø You know that plants can handle small temperature variations, but are exponentially more sensitive as the temperature variations increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Theoretically, which Loss function would you train your model on to limit the risk of killing plants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> üÜò Answer </summary>\n",
    "    \n",
    "By theory, you would use a Mean Square Error (MSE) Loss function. It would penalize outlier predictions and prevent your model from committing large errors. This would ensure smaller temperature variations and a lower risk for plants.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "The exponential sensitivity of plants to temperature variations suggests that errors with higher magnitude should be penalized more severely. This aligns with the characteristics of the **Mean Squared Error (MSE)** loss function. By squaring the errors, MSE amplifies the impact of larger deviations, which is suitable when predicting sensitive temperature variations to prevent significant temperature errors that could be detrimental to plant survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Standardise the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Glazing Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.041777</td>\n",
       "      <td>-1.785875</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>-1.470077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.760447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.041777</td>\n",
       "      <td>-1.785875</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>-1.470077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.760447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.041777</td>\n",
       "      <td>-1.785875</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>-1.470077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.760447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.041777</td>\n",
       "      <td>-1.785875</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>-1.470077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.760447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.284979</td>\n",
       "      <td>-1.229239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.198678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.760447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "0              2.041777     -1.785875  -0.561951  -1.470077             1.0   \n",
       "1              2.041777     -1.785875  -0.561951  -1.470077             1.0   \n",
       "2              2.041777     -1.785875  -0.561951  -1.470077             1.0   \n",
       "3              2.041777     -1.785875  -0.561951  -1.470077             1.0   \n",
       "4              1.284979     -1.229239   0.000000  -1.198678             1.0   \n",
       "\n",
       "   Glazing Area  \n",
       "0     -1.760447  \n",
       "1     -1.760447  \n",
       "2     -1.760447  \n",
       "3     -1.760447  \n",
       "4     -1.760447  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Extract the feature columns\n",
    "features = data.drop(columns=['Average Temperature'])\n",
    "\n",
    "# Fit the scaler on the features and transform them\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Create a new DataFrame with the scaled features\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "\n",
    "# Display the first few rows of the scaled dataset\n",
    "scaled_features_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to verify the theory by evaluating models optimized on different Loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares (MSE) Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **10-Fold Cross-validate** a Linear Regression model optimized by **Stochastic Gradient Descent** (SGD) on a **Least Squares Loss** (MSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.062743691028787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the target variable (labels)\n",
    "target = data['Average Temperature']\n",
    "\n",
    "# Initialize the SGD Regressor with the correct Mean Squared Error (MSE) loss\n",
    "sgd_regressor_mse = SGDRegressor(loss='squared_error')\n",
    "\n",
    "# Perform 10-Fold cross-validation\n",
    "cv_scores_mse = cross_val_score(sgd_regressor_mse, scaled_features, target, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive and calculate the mean\n",
    "mean_cv_score_mse = -np.mean(cv_scores_mse)\n",
    "\n",
    "mean_cv_score_mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute \n",
    "- the mean cross-validated R2 score and save it in the variable `r2`\n",
    "- the single biggest prediction error in ¬∞C of all your folds and save it in the variable `max_error_celsius`?\n",
    "\n",
    "(Tips: `max_error` is an accepted scoring metric in sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validated R¬≤ score of the model is: 0.8983\n",
      "The largest prediction error across all folds is: 9.84¬∞C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8983361912678971, 9.838834690046092)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score, max_error\n",
    "\n",
    "# Define the scorer for max error\n",
    "max_error_scorer = make_scorer(max_error, greater_is_better=False)\n",
    "\n",
    "# Perform 10-fold cross-validation for R2 score\n",
    "cv_scores_r2 = cross_val_score(sgd_regressor_mse, scaled_features, target, cv=10, scoring='r2')\n",
    "\n",
    "# Perform 10-fold cross-validation for max error\n",
    "cv_scores_max_error = cross_val_score(sgd_regressor_mse, scaled_features, target, cv=10, scoring=max_error_scorer)\n",
    "\n",
    "# Calculate the mean R2 score\n",
    "r2 = np.mean(cv_scores_r2)\n",
    "\n",
    "# Calculate the maximum prediction error across all folds (make positive)\n",
    "max_error_celsius = -np.min(cv_scores_max_error)\n",
    "\n",
    "print(f\"The mean cross-validated R¬≤ score of the model is: {r2:.4f}\")\n",
    "print(f\"The largest prediction error across all folds is: {max_error_celsius:.2f}¬∞C\")\n",
    "\n",
    "r2, max_error_celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE) Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we optimize our model on the MAE instead?\n",
    "\n",
    "‚ùì **10-Fold Cross-validate** a Linear Regression model optimized by **Stochastic Gradient Descent** (SGD) on a **MAE** Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Hints</summary>\n",
    "\n",
    "- MAE loss cannot be directly specified in `SGDRegressor`. It must be engineered by adjusting the right parameters\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2881477831885184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SGD Regressor with the \"epsilon_insensitive\" loss approximating MAE\n",
    "sgd_regressor_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0)\n",
    "\n",
    "# Perform 10-Fold cross-validation with 'neg_mean_absolute_error' scoring\n",
    "cv_scores_mae = cross_val_score(sgd_regressor_mae, scaled_features, target, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Convert negative MAE to positive and calculate the mean\n",
    "mean_cv_score_mae = -np.mean(cv_scores_mae)\n",
    "\n",
    "mean_cv_score_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute \n",
    "- the mean cross-validated R2 score, store it in `r2_mae`\n",
    "- the single biggest prediction error of all your folds, store it in `max_error_mae`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated R¬≤ score: 0.8764\n",
      "Single biggest prediction error: 11.19¬∞C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8764332071780456, 11.189636433776172)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 10-Fold cross-validation for R¬≤ score\n",
    "cv_scores_r2_mae = cross_val_score(sgd_regressor_mae, scaled_features, target, cv=10, scoring='r2')\n",
    "\n",
    "# Perform 10-Fold cross-validation for max error\n",
    "cv_scores_max_error_mae = cross_val_score(sgd_regressor_mae, scaled_features, target, cv=10, scoring=max_error_scorer)\n",
    "\n",
    "# Calculate the mean R¬≤ score\n",
    "r2_mae = np.mean(cv_scores_r2_mae)\n",
    "\n",
    "# Calculate the maximum prediction error across all folds (make positive)\n",
    "max_error_mae = -np.min(cv_scores_max_error_mae)\n",
    "\n",
    "print(f\"Mean cross-validated R¬≤ score: {r2_mae:.4f}\")\n",
    "print(f\"Single biggest prediction error: {max_error_mae:.2f}¬∞C\")\n",
    "\n",
    "r2_mae, max_error_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìWhich of the models you evaluated seems the most appropriate for your task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> üÜòAnswer </summary>\n",
    "    \n",
    "Although mean cross-validated r2 scores are approximately similar between the two models, the one optimized on a MAE has more chance to make larger mistakes from time to time, increasing the risk of killing plants!\n",
    "\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "To determine which model is most appropriate for predicting greenhouse temperature:\n",
    "\n",
    "1. **MSE-Optimized Model**:\n",
    "   - Mean R¬≤ Score: **0.8979**\n",
    "   - Biggest Prediction Error: **9.80¬∞C**\n",
    "\n",
    "2. **MAE-Optimized Model**:\n",
    "   - Mean R¬≤ Score: **0.8763**\n",
    "   - Biggest Prediction Error: **11.20¬∞C**\n",
    "\n",
    "**Analysis**:\n",
    "\n",
    "- **Accuracy**: The MSE-optimized model has a higher mean R¬≤ score, indicating it generally fits the data better than the MAE-optimized model.\n",
    "- **Biggest Error**: The MSE model also has a smaller largest prediction error compared to the MAE model.\n",
    "\n",
    "**Conclusion**:\n",
    "\n",
    "The model optimized with the MSE loss function appears to be more suitable. It has a higher R¬≤ score, meaning it explains more variance in the data, and its prediction errors are less extreme, which is important given the exponential sensitivity of plants to temperature variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ Check your code and push your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/ramzimalhas/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/ramzimalhas/code/ramzimalhas/05-ML/04-Under-the-hood/data-loss-functions/tests\n",
      "plugins: asyncio-0.19.0, anyio-3.7.1, typeguard-2.13.3\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "test_loss_functions.py::TestLossFunctions::test_max_error_order \u001b[32mPASSED\u001b[0m\u001b[32m   [ 33%]\u001b[0m\n",
      "test_loss_functions.py::TestLossFunctions::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m                [ 66%]\u001b[0m\n",
      "test_loss_functions.py::TestLossFunctions::test_r2_mae \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/loss_functions.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed loss_functions step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'loss_functions',\n",
    "    r2 = r2,\n",
    "    r2_mae = r2_mae,\n",
    "    max_error = max_error_celsius,\n",
    "    max_error_mae = max_error_mae\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
